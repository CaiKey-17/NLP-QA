{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca38587",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wikipedia-api tqdm\n",
    "import requests, json, time\n",
    "import wikipediaapi\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Khá»Ÿi táº¡o API tiáº¿ng Viá»‡t vá»›i user_agent há»£p lá»‡\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='vi',\n",
    "    user_agent='NLP_FinalProject/1.0 (Contact: caoky.sonha@gmail.com)'\n",
    ")\n",
    "\n",
    "NUM_PAGES = 10000\n",
    "topics = []\n",
    "\n",
    "# DÃ¹ng tqdm Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿n trÃ¬nh crawl\n",
    "for i in tqdm(range(NUM_PAGES // 10), desc=\"ğŸ“˜ Äang láº¥y bÃ i Wikipedia\"):\n",
    "    try:\n",
    "        res = requests.get(\n",
    "            \"https://vi.wikipedia.org/w/api.php\",\n",
    "            params={\n",
    "                \"action\": \"query\",\n",
    "                \"list\": \"random\",\n",
    "                \"rnnamespace\": 0,  # namespace=0 => bÃ i chÃ­nh\n",
    "                \"rnlimit\": 10,\n",
    "                \"format\": \"json\"\n",
    "            },\n",
    "            headers={\"User-Agent\": \"NLP_FinalProject/1.0 (Contact: caoky.sonha@gmail.com)\"}\n",
    "        )\n",
    "        data = res.json()\n",
    "\n",
    "        # Ghi log má»—i 100 vÃ²ng\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"ÄÃ£ xá»­ lÃ½ {i*10} bÃ i... (tá»•ng hiá»‡n táº¡i: {len(topics)})\")\n",
    "\n",
    "        for page in data.get(\"query\", {}).get(\"random\", []):\n",
    "            topics.append(page[\"title\"])\n",
    "\n",
    "        time.sleep(0.3)  # trÃ¡nh spam API\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Lá»—i á»Ÿ vÃ²ng {i}: {e}\")\n",
    "        time.sleep(1)\n",
    "\n",
    "print(f\"\\nâœ… HoÃ n táº¥t! Láº¥y ngáº«u nhiÃªn Ä‘Æ°á»£c {len(topics)} bÃ i viáº¿t.\")\n",
    "\n",
    "# LÆ°u danh sÃ¡ch tiÃªu Ä‘á» Ä‘á»ƒ dÃ¹ng láº¡i\n",
    "with open(\"wiki_topics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(topics, f, ensure_ascii=False, indent=2)\n",
    "print(\"ğŸ’¾ ÄÃ£ lÆ°u danh sÃ¡ch chá»§ Ä‘á» vÃ o file 'wiki_topics.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccf4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº£i danh sÃ¡ch topics Ä‘Ã£ lÆ°u\n",
    "with open(\"/kaggle/working/wiki_topics.json\", encoding=\"utf-8\") as f:\n",
    "    topics = json.load(f)\n",
    "\n",
    "# Khá»Ÿi táº¡o Wikipedia API (váº«n giá»¯ user_agent)\n",
    "wiki = wikipediaapi.Wikipedia(\n",
    "    language='vi',\n",
    "    user_agent='NLP_FinalProject/1.0 (Contact: caoky.sonha@gmail.com)'\n",
    ")\n",
    "\n",
    "contexts = []\n",
    "\n",
    "# Crawl tá»«ng bÃ i, cÃ³ thanh tiáº¿n trÃ¬nh\n",
    "for topic in tqdm(topics, desc=\"ğŸ“„ Äang láº¥y ná»™i dung bÃ i Wikipedia\"):\n",
    "    try:\n",
    "        page = wiki.page(topic)\n",
    "        if not page.exists():\n",
    "            continue\n",
    "\n",
    "        text = page.text.strip()\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        # Cáº¯t bÃ i thÃ nh Ä‘oáº¡n\n",
    "        paragraphs = text.split('\\n')\n",
    "        for p in paragraphs:\n",
    "            words = p.split()\n",
    "            if 40 <= len(words) <= 150: \n",
    "                contexts.append({\n",
    "                    \"topic\": topic,\n",
    "                    \"context\": p.strip()\n",
    "                })\n",
    "\n",
    "        # log Ä‘á»‹nh ká»³\n",
    "        if len(contexts) % 1000 == 0:\n",
    "            print(f\"ÄÃ£ thu Ä‘Æ°á»£c {len(contexts)} Ä‘oáº¡n...\")\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Lá»—i á»Ÿ bÃ i '{topic}': {e}\")\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"\\nâœ… HoÃ n táº¥t! Thu Ä‘Æ°á»£c {len(contexts)} Ä‘oáº¡n vÄƒn usable tá»« {len(topics)} bÃ i.\")\n",
    "\n",
    "# LÆ°u file káº¿t quáº£\n",
    "with open(\"raw_contexts_large.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(contexts, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"ÄÃ£ lÆ°u dá»¯ liá»‡u vÃ o 'raw_contexts_large.json'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
